# OpenManager Vibe V4 초기 분석 및 진단 보고서

## 1. 프로젝트 개요

OpenManager Vibe V4는 자연어 기반 서버 분석 및 모니터링 시스템입니다. 관리자가 자연어로 서버 상태에 대한 질문을 하면, 시스템이 이를 분석하여 관련 정보를 제공하는 것을 목표로 합니다. 현재 프로젝트는 프론트엔드와 백엔드(MCP Lite Server)로 구성되어 있으며, 데모 및 시연 환경에 초점을 맞춘 경량화된 AI 기능을 제공합니다.

## 2. 코드베이스 구조

프로젝트는 크게 `frontend`와 `mcp-lite-server` 두 개의 주요 디렉토리로 구성됩니다.

*   **`frontend/`**: 순수 HTML, CSS, JavaScript로 작성된 사용자 인터페이스 로직을 포함합니다.
    *   `index.html`: 메인 랜딩 페이지.
    *   `server_dashboard.html`: 서버 모니터링 대시보드.
    *   `ai_processor.js`: 프론트엔드 AI 로직 (규칙 기반).
    *   `data_processor.js`: 데이터 처리 및 시각화 로직.
    *   `config.js`: API 엔드포인트 등 설정 파일.
*   **`mcp-lite-server/`**: Node.js와 Express.js 기반의 백엔드 서버입니다.
    *   `server.js`: 주 서버 로직 및 API 엔드포인트 정의.
    *   `ai_agent.js`: 백엔드 AI 로직 (통계 기반).
    *   `context/`: `/query` 엔드포인트에서 사용되는 텍스트 파일 기반 컨텍스트 저장.
    *   `routes/`: 라우팅 로직 (현재 `logs.js` 포함).
    *   `utils/`: 유틸리티 스크립트 (예: `k8sDataGenerator.js`).
*   **`README.md`**: 프로젝트 전반적인 설명, 구조, 배포 정보 등을 포함합니다.
*   **`package.json`**: 프로젝트 의존성 및 실행 스크립트를 정의합니다.

## 3. 주요 기능

*   **자연어 질의 인터페이스**: 사용자가 프론트엔드에서 자연어로 서버 관련 질문을 입력할 수 있습니다.
*   **서버 모니터링 대시보드**: 서버 상태 및 주요 메트릭(CPU, 메모리, 디스크 등)을 시각적으로 표시합니다.
*   **문제 분석 및 해결책 제안**: 정의된 패턴에 따라 문제를 감지하고, 가능한 원인과 해결책을 제시합니다.
*   **데이터 필터링 및 보고서 생성**: 프론트엔드에서 가상 데이터를 기반으로 필터링 및 간단한 보고서 생성 기능을 제공합니다.
*   **경량화된 AI 응답**: LLM 없이 규칙 및 간단한 통계 기반으로 AI와 유사한 사용자 경험을 제공하려 시도합니다.

## 4. "LLM 없는 AI 에이전트" 구성 요소 상세 분석

현재 시스템은 실제 대규모 언어 모델(LLM)을 사용하지 않고, 다음과 같은 구성 요소들을 통해 "AI 에이전트"와 유사한 기능을 구현하고 있습니다.

### 4.1. `mcp-lite-server/server.js`의 `/query` 엔드포인트

*   **기능**: 프론트엔드로부터 전달받은 `query` (사용자 질문)와 `context` (컨텍스트 파일명)를 기반으로 응답을 생성합니다.
*   **동작 방식**:
    1.  요청받은 `context` 이름에 해당하는 `.txt` 파일을 `context/` 디렉토리에서 읽습니다. (예: `server-status.txt`)
    2.  읽어온 파일 내용을 줄(line) 단위로 분리합니다.
    3.  사용자 `query`를 공백 기준으로 단어로 분리한 후, 각 단어가 파일의 어떤 줄에 포함되어 있는지 검사합니다.
    4.  첫 번째로 일치하는 줄을 찾아 응답으로 반환합니다. 일치하는 내용이 없으면 "관련 내용을 찾지 못했습니다"를 반환합니다.
*   **한계점**:
    *   단순 문자열 포함 여부만 확인하므로, 문맥 이해나 유연한 질의 처리가 불가능합니다.
    *   사전에 정의된 텍스트 파일에 의존적이므로, 다양한 질문에 대한 동적인 응답 생성이 어렵습니다.
    *   `context` 파일 관리가 수동적이며, 확장이 번거로울 수 있습니다.
*   **개선 방안**:
    *   키워드 추출, 유사도 분석 등 기본적인 NLP 기술 도입.
    *   응답 포맷을 좀 더 구조화하여 다양한 정보를 포함할 수 있도록 개선.

### 4.2. `frontend/ai_processor.js`

*   **기능**: 프론트엔드에서 사용자 질의를 분석하고, 정의된 규칙 및 문제 패턴에 따라 응답, 분석 결과, 해결책 등을 생성합니다.
*   **동작 방식**:
    1.  **데이터 관리**: `serverData` (가상 서버 데이터) 및 `historicalData` (시계열 데이터)를 관리합니다. `window.serverData` 또는 `serverDataUpdated` 이벤트를 통해 데이터를 업데이트합니다.
    2.  **문제 패턴 정의 (`initProblemPatterns`)**: CPU/메모리/디스크 임계치 초과, 서비스 중단, 특정 오류 메시지 발생 등 다양한 문제 상황을 `critical` 또는 `warning` 수준으로 사전 정의합니다. 각 패턴에는 조건, 설명, 가능한 원인, 해결책이 포함됩니다.
    3.  **서버 상태 평가 (`getEffectiveServerStatus`)**: 정의된 문제 패턴을 기반으로 개별 서버의 상태를 `critical`, `warning`, `normal`로 평가합니다.
    4.  **질의 분석 (`analyzeQuery`)**: 사용자 입력(`query`)을 소문자화하고 정규화한 후, 키워드 매칭을 통해 요청 유형(일반 조회, 문제 분석, 해결책 요청, 보고서 요청), 대상 메트릭(CPU, 메모리 등), 임계값, 시간 범위 등을 분석합니다.
    5.  **응답 생성 (`generateDataResponse`, `generateProblemAnalysis`, `generateSolutions`, `generateReportDownloadLink`)**: 분석된 요청 유형에 따라 적절한 응답을 생성합니다.
        *   메트릭 조회: 특정 메트릭(CPU, 메모리, 디스크, 네트워크)에 대한 통계 및 임계치 초과 서버 목록을 제공합니다.
        *   문제 분석: 감지된 모든 문제 목록과 영향받는 서버 수를 요약하여 보여줍니다.
        *   해결책 제공: 특정 문제 ID에 대해 사전 정의된 원인과 해결책을 제시합니다.
        *   보고서 생성: 가상의 보고서 다운로드 링크를 생성합니다. (실제 파일 생성 기능은 없음)
    6.  **문제 감지 및 보고서 생성 (`detectProblems`, `generateErrorReport`)**: `problemPatterns` 외에 추가적인 규칙으로 문제를 감지하고, 이를 기반으로 마크다운 형식의 상세 보고서를 생성합니다. (실제 사용자 인터페이스에 직접적으로 연결되어 사용되는지는 추가 확인 필요)
*   **상호작용**:
    *   주로 프론트엔드 내부의 가상 데이터를 사용합니다.
    *   `fetchFromMCP` 함수를 통해 백엔드의 `/query` 엔드포인트와 통신을 시도하지만, 현재 `processQuery` 함수는 `fetchFromMCP`의 결과를 우선하고, 실패 시 로컬의 `keywordMatchAnswer` (매우 기본적인 키워드 매칭)를 사용하는 이중 구조로 되어 있어 혼란을 야기할 수 있습니다. 전역 `window.processQuery`와 `export async function processQuery`의 관계 및 실제 호출 흐름이 명확하지 않습니다.
*   **한계점**:
    *   모든 로직이 프론트엔드에 집중되어 있어, 복잡한 분석이나 대규모 데이터 처리에 부적합합니다.
    *   규칙 기반이므로 새로운 문제 유형이나 다양한 사용자 질문에 대한 유연성이 낮습니다.
    *   `analyzeQuery`의 키워드 매칭 방식이 정교하지 않아, 복합적인 질문 해석에 한계가 있습니다.
*   **개선 방안**:
    *   주요 분석 로직을 백엔드로 이전하여 성능 및 확장성 확보.
    *   규칙 관리 시스템을 도입하여 패턴 추가/수정을 용이하게 개선.
    *   질의 분석 로직 고도화 (예: 간단한 의도 분류 모델 사용).

### 4.3. `mcp-lite-server/ai_agent.js` (백엔드의 `/api/ai/query` 엔드포인트)

*   **기능**: 백엔드에서 서버 메트릭 데이터를 받아 통계적 분석을 수행하고, 이를 기반으로 간단한 자연어 응답을 생성합니다.
*   **동작 방식**:
    1.  **데이터 분석 (`analyzeMetrics`)**:
        *   입력된 서버 메트릭(CPU, 메모리, 디스크 사용률 등)에 대해 각 항목별로 Z-score를 계산합니다.
        *   Z-score가 2.0을 초과하는 경우 해당 메트릭에 대해 `_anomaly` (예: `cpu_anomaly`) 플래그를 `true`로 설정하여 이상 징후를 표시합니다.
    2.  **자연어 응답 생성 (`generateNaturalResponse`)**:
        *   사용자 `question`에 포함된 키워드 (예: "cpu 높", "메모리 누수", "장애 많")를 정규표현식으로 매칭합니다.
        *   매칭된 키워드에 따라 분석된 데이터를 활용하여 응답을 생성합니다.
            *   CPU 관련 질문: CPU 사용률 상위 서버 목록과 함께 `cpu_anomaly`가 감지된 서버를 언급하며 가능한 원인과 조치 사항을 제시합니다.
            *   메모리 누수 의심 질문: `memory_anomaly`가 감지된 서버 목록과 함께 조치 사항을 제시합니다.
            *   장애 관련 질문: `incident` 필드가 'Normal'이 아닌 서버를 필터링하고, 장애 발생 빈도가 높은 서버와 주요 이벤트를 언급합니다.
        *   일치하는 키워드가 없으면 "질문을 이해하지 못했습니다."를 반환합니다.
    3.  **컨텍스트 업데이트 (`updateContext`)**: 사용자 ID별로 마지막 질문, 응답, 분석 결과를 `CONTEXT_HISTORY` 객체에 저장합니다. (현재 이 컨텍스트는 다음 요청 시 `generateNaturalResponse` 함수에 전달되지만, 실제 응답 생성 로직에서 활용되지는 않는 것으로 보입니다.)
*   **상호작용**:
    *   `mcp-lite-server/server.js`의 `/api/ai/query` 엔드포인트를 통해 호출됩니다.
    *   `k8sDataGenerator.getCurrentMetrics()`로부터 최신 서버 메트릭 데이터를 받아 사용합니다.
*   **한계점**:
    *   Z-score 기반 이상 탐지는 간단하지만, 다양한 상황에 대한 정교한 판단에는 한계가 있습니다.
    *   자연어 응답 생성이 단순 키워드 매칭과 미리 정의된 템플릿에 의존합니다.
    *   `CONTEXT_HISTORY`가 활용되지 않아 대화의 연속성을 가지기 어렵습니다.
*   **개선 방안**:
    *   다양한 통계적 분석 기법 또는 간단한 머신러닝 모델 도입 고려.
    *   응답 생성 로직을 좀 더 유연하고 확장 가능하도록 개선.
    *   컨텍스트 정보를 실제 응답 생성에 활용하여 보다 맥락에 맞는 답변 제공.

## 5. 잠재적 개선 영역 및 기능적 한계점 요약

*   **AI 기능의 분산 및 중복**: 유사한 AI 기능(질의 처리, 응답 생성)이 프론트엔드(`ai_processor.js`)와 백엔드(`server.js`의 `/query`, `ai_agent.js`)에 분산되어 있고, 일부 중복되는 로직(키워드 매칭)이 존재합니다. 이는 유지보수를 어렵게 만들고 기능 확장을 더디게 할 수 있습니다.
*   **제한적인 자연어 이해(NLU)**: 현재 시스템은 주로 단순 키워드 매칭에 의존하므로, 복잡하거나 다양한 형태의 사용자 질문을 이해하고 처리하는 데 명확한 한계가 있습니다.
*   **데이터 의존성**: 프론트엔드의 AI 로직은 `fixed_dummy_data.js` 또는 이벤트 주입 데이터에 크게 의존하고 있으며, 백엔드 `/query`는 `context/` 내 텍스트 파일에, `/api/ai/query`는 `k8sDataGenerator`의 가상 데이터에 의존합니다. 실제 운영 환경의 다양한 데이터를 통합하고 처리하는 방안이 필요합니다.
*   **확장성 및 유지보수성**: 현재의 규칙/패턴 기반 시스템은 새로운 규칙이나 컨텍스트를 추가할 때 직접 코드를 수정해야 하는 경우가 많아 확장성과 유지보수성이 떨어질 수 있습니다.
*   **컨텍스트 활용 미흡**: `mcp-lite-server/ai_agent.js`에서 컨텍스트를 저장하지만 실제 응답 생성에 활용하지 않는 등, 대화의 연속성이나 개인화된 응답 제공 기능이 부족합니다.

## 6. 결론

OpenManager Vibe V4는 LLM 없이도 AI와 유사한 경험을 제공하려는 시도를 보여주는 프로젝트입니다. 프론트엔드의 규칙 기반 시스템과 백엔드의 간단한 텍스트 매칭 및 통계 기반 분석을 통해 기본적인 자연어 질의응답 기능을 구현했습니다.

향후 실제 운영 환경에서 활용되기 위해서는 자연어 이해 능력 강화, AI 로직의 통합 및 고도화, 실제 데이터 연동, 확장성 있는 시스템 아키텍처 설계 등의 개선이 필요해 보입니다. 특히, 분산된 AI 관련 로직을 명확한 역할에 따라 재정의하고 통합하는 작업이 우선적으로 고려될 수 있습니다.
